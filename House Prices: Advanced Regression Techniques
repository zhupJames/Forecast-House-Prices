# Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity
# to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number
# of bedrooms or a white-picket fence.

# With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to
# predict the final price of each home.

# The potential for creative feature engineering provides a rich opportunity for fun and learning. This dataset lends itself to advanced
# regression techniques like random forests and gradient boosting with the popular XGBoost library. We encourage Kagglers to create
# benchmark code and tutorials on Kernels for community learning. Top kernels will be awarded swag prizes at the competition close. 

# I use R to do this competition. I also do a Python version for practice.

# These are all the packages that I use for this competition
library(ggplot2)
library(readr)
library(MASS)
library(plyr)
library(dplyr)
library(lars)
library(moments)
library(caret)
library(corrplot)
library(gbm)
library(randomForest)
library(tidyr)
library(rpart)

# input the data. There are two csv documents. train.csv is for data trainning. test.csv is for data testing.
setwd("C:/Users/Pengwei Zhu/Downloads/House Prices Kaggle")
train_org <- read.csv("train.csv", header = TRUE)
test_org <- read.csv("test.csv", header = TRUE)

# check the type of the two data frame
str(train)
str(test)

# We can see that train has one more variable than test. So I compare all the variables in train and test, and I find that SalePrice is
# missing in test. Therefore, I need to separate train data into two parts, one for train and another for test which is for testing the
# forecasting accuracy of the model generated from train.

# create a sample vector of test values
testid <- sample(1:nrow(train_org), nrow(train_org)/4, replace = F)

# test dataset
test <- train_org[testid,]

# train dataset
train <- train_org[-testid,]

# After generating the dataset of train and test, we need to check the data frame again to make sure the data is correct.
str(train)
str(test)
summary(train)
summary(test)

# After the summary, we saw there are a lot of NAs in the data frame. Then we need to clean the data since we will have trouble during
# the regression if we just leave NAs in the dataset.
# Since both train and test have NAs, we have to combine them together and then we can clean the data in order to avoid the type of two
# datasets are different which may cause R cannot do regression.
train$train <- 1
test$train <- 0
combined <- rbind(train,test)

# Here is the function of RMSE which we use this to check how good the model does.
RMSE <- function(x,y){
  a <- sqrt(sum((log(x)-log(y))^2)/length(y))
  return(a)
}

# check missing value
Missing_indices <- sapply(combined, function(x)sum(is.na(x)))
Missing_Summary <- data.frame(index = names(combined), Missing_Values = Missing_indices)
Missing_Summary[Missing_Summary$Missing_Values > 0,]

# we can see there are a great number of NAs in some variables, and I find that some of NAs do not mean they are unknown but they mean
# none. Therefore, we'd better change the values of these NAs to "none"

# Alley
levels(combined$Alley) <- c(levels(combined$Alley), "None")
combined$Alley[is.na(combined$Alley)] <- "None"

# MiscFeature
levels(combined$MiscFeature) <- c(levels(combined$MiscFeature), "None")
combined$MiscFeature[is.na(combined$MiscFeature)] <- "None"

# Fence
levels(combined$Fence) <- c(levels(combined$Fence), "None")
combined$Fence[is.na(combined$Fence)] <- "None"

# Pool
levels(combined$PoolQC) <- c(levels(combined$PoolQC), "None")
combined$PoolQC[is.na(combined$PoolQC)] <- "None"

# Fireplace Qu
levels(combined$FireplaceQu) <- c(levels(combined$FireplaceQu), "None")
combined$FireplaceQu[is.na(combined$FireplaceQu)] <- "None"

# Garage, I saw GarageType, GarageYrBlt, GarageFinish, GarageQual, GarageCond which have the same number of NAs. So I think they may
# relate to each other and they may all shows that there is no Garage.
# Therefore, next I should do is to check whether the NAs with the same ID in different variables.
# Caution, some variables like "GarageYrBlt" are integer which is not character, so we change NAs to "0". And the variable "GarageYrBlt"
# shows the year when the garage was built. Since NAs in this varialbe means no garage, we make it to 0 since the year is bigger means it
# is newer and has more value, and no garage should have less value than has garage, so we set the value to 0 is a good choice.
title <- c("GarageType", "GarageYrBlt", "GarageFinish", "GarageQual", "GarageCond")
result <- c()
for (i in 1:(length(title)-1)) {
  if (identical(as.character(combined[is.na(combined[,title[i]]) ,title[i]]), as.character(combined[is.na(combined[,title[i+1]]),
                                                                                                    title[i+1]]))) {
    result[i] <- paste(title[i], "equal", title[i+1], sep = " ")
  }else {
    result[i] <- paste(title[i], "not equal", title[i+1], sep = " ")
  }
}
print(result)

# Since they all shows the same ID, we can change them all to "nonw"
for(i in 1:length(title)){
  if (is.integer(combined[,title[i]])){
    combined[,title[i]][which(is.na(combined[,title[i]]))] <- as.integer(0)
  } else {levels(combined[,title[i]]) <- c(levels(combined[,title[i]]), "None")
  combined[,title[i]][is.na(combined[,title[i]])] <- "None"
  }
}

# Masonry veneer, the same problem with Garage
title <- c("MasVnrArea", "MasVnrType")
result <- c()
for (i in 1:(length(title)-1)) {
  if (identical(as.character(combined[is.na(combined[,title[i]]) ,title[i]]), as.character(combined[is.na(combined[,title[i+1]]),
                                                                                                    title[i+1]]))) {
    result[i] <- paste(title[i], "equal", title[i+1], sep = " ")
  }else {
    result[i] <- paste(title[i], "not equal", title[i+1], sep = " ")
  }
}
print(result)
for(i in 1:length(title)){
  if (is.integer(combined[,title[i]])){
    combined[,title[i]][which(is.na(combined[,title[i]]))] <- as.integer(0)
  } else {levels(combined[,title[i]]) <- c(levels(combined[,title[i]]), "None")
  combined[,title[i]][is.na(combined[,title[i]])] <- "None"
  }
}

# Basement, the same problem with Garage but the ID may different in different variable. For example, in the same entry, "BsmtFinType1" 
# may shows unfinished, but in "BsmtCond" may shows NA which means no basement.
title <- c("BsmtQual", "BsmtCond", "BsmtExposure", "BsmtFinType1", "BsmtFinType2")
for(i in 1:length(title)){
  if (is.integer(combined[,title[i]])){
    combined[,title[i]][which(is.na(combined[,title[i]]))] <- as.integer(0)
  } else {levels(combined[,title[i]]) <- c(levels(combined[,title[i]]), "None")
  combined[,title[i]][is.na(combined[,title[i]])] <- "None"
  }
}

# LotFrontage, since NAs in LotFrontage means unknown, I will assign them with the mean of LotFrontage in order to reduce the effect of
# NAs in LotFrontage.
combined$LotFrontage[which(is.na(combined$LotFrontage))] <- mean(combined$LotFrontage,na.rm = T)

# Electrical, NAs in Electrical means unknown. Since it is not a numeric variable and there is only one NA, I would like to remove this
# entry.
combined <- combined[!is.na(combined$Electrical),]

# check again to make sure there is no missing value
Missing_indices <- sapply(combined, function(x)sum(is.na(x)))
Missing_Summary <- data.frame(index = names(combined), Missing_Values = Missing_indices)
Missing_Summary[Missing_Summary$Missing_Values > 0,]

# wonderful! Now there is no NAs any more. We can seperate the data frame into train and test again.
train <- combined[combined$train==1,]
test <- combined[combined$train==0,]
test$train <- NULL
train$train <- NULL

# change the data type to make sure they are match
str(train)
str(test)

# now we are going to do forecasting. There are two methods I can use. One is random forest, another is GBM. I will do the both and
# compare the two RMSE and find out which one is the best.

# Random Forest
model <- randomForest(SalePrice ~., data = train, method = "anova",
                      ntree = 300,
                      mtry = 26,
                      replace = F,
                      nodesize = 1,
                      importance = T)
predict <- predict(model, test)
RMSE1 <- RMSE(predict, test$SalePrice)
RMSE1 <- round(RMSE1, digits = 3)
plot1 <- predict-test$SalePrice

# GBM

fitControl <- trainControl(## 10-fold CV
  method = "repeatedcv",
  number = 10,
  ## repeated ten times
  repeats = 10)
gbmFit1 <- train(SalePrice ~ ., data = train, 
                 method = "gbm", 
                 trControl = fitControl,
                 ## This last option is actually one
                 ## for gbm() that passes through
                 verbose = FALSE)
gbmFit1

model <- gbm(SalePrice ~., data = train, distribution = "laplace",
             shrinkage = 0.1,
             interaction.depth = 3,
             bag.fraction = 0.75,
             n.minobsinnode = 10,
             cv.folds = 10,
             keep.data = F,
             verbose = F,
             n.trees = 150)
predict <- predict(model, test, n.trees = 150)
RMSE2 <- RMSE(predict, test$SalePrice)
RMSE2 <- round(RMSE2, digits = 3)
plot2 <- predict-test$SalePrice

# Compare the two RMSE and choose the smallest one.
RMSE1 > RMSE2
